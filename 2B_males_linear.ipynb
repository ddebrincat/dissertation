{"cells":[{"cell_type":"markdown","metadata":{"id":"1mFEiIzSRIfM"},"source":["### Importing relevant Libraries :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPFYmpjEQy9A"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","import seaborn as sns\n","import scipy.stats as ss\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","import math\n","\n","plt.rcParams['figure.dpi'] = 300\n","plt.rcParams['savefig.dpi'] = 300\n","sns.set()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpu-U5UmR1Nx"},"outputs":[],"source":["# Reading csv file and setting matrix as a dataframe. \n","import pandas as pd\n","\n","df = pd.read_csv('./mami_data_file.csv', sep = ',', parse_dates=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rZNtO6yuKf0"},"outputs":[],"source":["cleanup = {'CaConRel':{1: 0, 2: 1, 3 : ' '},'q_15':{'15b':0, '15a':1}}\n","\n","df.replace(cleanup, inplace=True)\n","\n","# The empty spaces are being replaced to NaNs i.e. missing values\n","\n","df.replace(' ', np.NaN, inplace=True)\n","\n","df.rename(columns = {'q_15':'Smoke_status', 'q_23':'Alcohol_status'}, inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"uwZl72GCoF1y"},"source":["### Determining the variables of interest:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEFID_U1PzX_"},"outputs":[],"source":["cols_tobe_selected = df[['TRIG_FOL_ALL','Age','Gender', 'CaConRel','Smoke_status','Alcohol_status', 'CHOL','q_132_1_Syst','q_132_2_Syst','HDLC', 'HBA1C','BMI']]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhlTLhlLs34C"},"outputs":[],"source":["# Working on a subset of the dataset. This is needed before removing the missing \n","# values so that most of the rows are still conserved\n","\n","cols_tobe_selected = df[['TRIG_FOL_ALL','Age','Gender', 'CaConRel','Smoke_status','Alcohol_status', 'CHOL','q_132_1_Syst','q_132_2_Syst','HDLC', 'HBA1C','BMI']]\n","\n","working_df = cols_tobe_selected.dropna()\n","working_df.reset_index(drop=True, inplace=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wkp7YCCqxnlW"},"outputs":[],"source":["# Specifying Males only\n","working_df_males = working_df[working_df['Gender'] == '2']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1672221925646,"user":{"displayName":"Daniella Keen","userId":"08987638985144891935"},"user_tz":-60},"id":"0wbgqN03Sa0H","outputId":"57fcb86e-dd28-4420-f3be-5b036efd9b10"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self[k1] = value[k2]\n"]}],"source":["# Setting specific columns as numeric instead of object\n","\n","obj_to_numeric_cols = ['Age','TRIG_FOL_ALL','CaConRel','CHOL','q_132_1_Syst','q_132_2_Syst', 'HDLC','BMI', 'HBA1C']\n","\n","working_df_males[obj_to_numeric_cols]= working_df_males[obj_to_numeric_cols].apply(pd.to_numeric)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_vs9bXkSam_"},"outputs":[],"source":["# Setting specific columns as string instead of float\n","\n","num_to_obj_cols = working_df_males.loc[:, ~working_df_males.columns.isin(obj_to_numeric_cols)].columns\n","\n","working_df_males[num_to_obj_cols]= working_df_males[num_to_obj_cols].astype(str)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1672221925646,"user":{"displayName":"Daniella Keen","userId":"08987638985144891935"},"user_tz":-60},"id":"1aAZErnciuNU","outputId":"b00c7b61-5c7e-4541-b386-d5a466350dd1"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-e93997d3b128>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  working_df_males['Avr_syst']= working_df_males[['q_132_1_Syst','q_132_2_Syst']].mean(axis = 1)\n"]}],"source":["# Calculating the mean systolic bp by adding Syst_bp_1 to Syst_bp_2 and diving by 2 in another column\n","working_df_males['Avr_syst']= working_df_males[['q_132_1_Syst','q_132_2_Syst']].mean(axis = 1)"]},{"cell_type":"markdown","metadata":{"id":"nvAKgFaQ8gDW"},"source":["### Creating Dummy Variables :"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1672221926007,"user":{"displayName":"Daniella Keen","userId":"08987638985144891935"},"user_tz":-60},"id":"toT28Zph8exc","outputId":"cda26a93-cf03-479e-968e-ad72239af5d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['TRIG_FOL_ALL', 'Age', 'CaConRel', 'CHOL', 'q_132_1_Syst',\n","       'q_132_2_Syst', 'HDLC', 'HBA1C', 'BMI', 'Avr_syst', 'Smoke_status_1.0',\n","       'Alcohol_status_2'],\n","      dtype='object')"]},"metadata":{},"execution_count":11}],"source":["# Dummies created automatically for the object type variables. Original variables\n","# are dropped to folow the N-1 rule \n","\n","working_df_males = pd.get_dummies(working_df_males, drop_first=True)\n","working_df_males.columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEOQM--rUetP"},"outputs":[],"source":["# Correlation Heatmap\n","\n","plt.figure(figsize=(15, 10))\n","sns.heatmap(abs(working_df_males.corr()))\n","plt.title(\"Correlation Heat Map\");"]},{"cell_type":"markdown","metadata":{"id":"IVT2ZqJzwM0_"},"source":["### Linear Regression Model :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LxFdajkptNEE"},"outputs":[],"source":["inputs_cases = working_df_males[working_df_males['CaConRel'] == 1]\n","inputs_ctrls = working_df_males[working_df_males['CaConRel'] == 0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpKqux3kwJjg"},"outputs":[],"source":["# Declaring the Inputs (Predictors) and Target\n","\n","targets_cases = inputs_cases['TRIG_FOL_ALL']\n","targets_ctrls = inputs_ctrls['TRIG_FOL_ALL']\n","\n","inputs_cases = inputs_cases.drop(['TRIG_FOL_ALL','CaConRel','q_132_1_Syst', 'q_132_2_Syst'],axis =1)\n","inputs_ctrls = inputs_ctrls.drop(['TRIG_FOL_ALL','CaConRel','q_132_1_Syst', 'q_132_2_Syst'],axis =1)\n","\n","cols_for_scaling_cases = inputs_cases.loc[:, ~inputs_cases.columns.isin(['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst'])].columns\n","cols_for_scaling_ctrls = inputs_ctrls.loc[:, ~inputs_ctrls.columns.isin(['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst'])].columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dowLNEFt-iV6"},"outputs":[],"source":["# Controls are split into training and testing sets. The training set (80%) will be used to train the model and the testing set will be concatenated with the \n","# cases to test the model and get the predicted triglycerides(TG).\n","\n","inputs_ctrls_train, inputs_ctrls_test, targets_ctrls_train, targets_ctrls_test = train_test_split(inputs_ctrls, targets_ctrls, train_size = .8, random_state = 999)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UES3cDtxCos"},"outputs":[],"source":["# Test_set and test_target_set will be used to get the predicted TG for both cases and controls\n","\n","test_set = pd.concat([inputs_ctrls_train, inputs_ctrls_test, inputs_cases])\n","test_target_set = pd.concat([targets_ctrls_train, targets_ctrls_test, targets_cases])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDSTQdDMwh4g"},"outputs":[],"source":["# Standardising the continuous variables only after splitting\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","\n","inputs_ctrls_test_scaled = scaler.fit_transform(inputs_ctrls_test[['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst']])\n","inputs_ctrls_test_scaled_df = pd.DataFrame(data=inputs_ctrls_test_scaled, columns= ['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst'], index=inputs_ctrls_test.index) \n","inputs_ctrls_test = pd.concat([inputs_ctrls_test_scaled_df, inputs_ctrls_test[cols_for_scaling_ctrls]], axis=1)\n","\n","# \n","\n","inputs_ctrls_scaled = scaler.fit_transform(inputs_ctrls_train[['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst']])\n","inputs_ctrls_scaled_df = pd.DataFrame(data=inputs_ctrls_scaled, columns= ['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst'], index=inputs_ctrls_train.index) \n","inputs_ctrls_train = pd.concat([inputs_ctrls_scaled_df, inputs_ctrls_train[cols_for_scaling_ctrls]], axis=1)\n","\n","##\n","\n","inputs_cases_scaled = scaler.fit_transform(test_set[['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst']])\n","inputs_cases_scaled_df = pd.DataFrame(data=inputs_cases_scaled, columns= ['Age','CHOL', 'HDLC', 'HBA1C','BMI','Avr_syst'], index=test_set.index) \n","inputs_cases = pd.concat([inputs_cases_scaled_df, test_set[cols_for_scaling_cases]], axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvryddlGGiSx"},"outputs":[],"source":["#x_train and y_train = 80% of controls to train the model\n","\n","x_test = inputs_cases \n","x_train = inputs_ctrls_train \n","\n","\n","y_test = test_target_set\n","y_train = targets_ctrls_train\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ts84JEhSG2uM"},"outputs":[],"source":["# Fitting the Regression Model using the training dataset\n","\n","reg = LinearRegression().fit(x_train, y_train)\n"]},{"cell_type":"markdown","metadata":{"id":"HSiCjmPmaE5X"},"source":["Testing Performance of Trained Linear Regression Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-sQu-J_aBEg"},"outputs":[],"source":["# y_hat_train refers to the predictions using the training set\n","\n","y_hat_train = reg.predict(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCDFUHyuZRSR"},"outputs":[],"source":["# Plotting feature Importance chart of the trained model\n","\n","def plot_feat_import(reg, xtrain_df, y_train):\n","  r_squared = reg.score(xtrain_df, y_train)\n","  \n","  coef_results = pd.DataFrame(data=list(reg.coef_.reshape(1, -1)), columns=list(xtrain_df.columns))\n","\n","  plt.figure(figsize=(15, 15))\n","  plt.bar(coef_results.columns, coef_results.values[0])\n","  plt.xticks(rotation=90, size = 20);\n","  plt.yticks( size = 20);\n","  plt.title(\"Feature Importance Chart\", size =20, weight = 'bold');\n","  plt.ylabel(\"Coefficients\", size = 20)\n","  plt.xlabel(\"Features\", size =20)\n","  return coef_results\n","\n","coef_results = plot_feat_import(reg, x_train, y_train)\n","\n","coef_results"]},{"cell_type":"markdown","metadata":{"id":"jrtI-4UiNF0b"},"source":["### Testing Linear Regression Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9YqFzsRr9PS"},"outputs":[],"source":["# Predicting using 20% of the controls (validation set)\n","\n","Pred_ctrls = reg.predict(inputs_ctrls_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lmBL9T_LaHG"},"outputs":[],"source":["# Predict response of a combination of x_train and x_test (testing set)\n","\n","x_conc = x_test\n","y_conc = test_target_set\n","y_hat_conc = reg.predict(x_conc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZL23iGlZRqc"},"outputs":[],"source":["# training set (80% of controls)\n","\n","print(\"RMSE:\",math.sqrt(mean_squared_error(y_train, y_hat_train)))\n","print(\"R2:\", r2_score(y_train, y_hat_train))\n","print(\"MAE:\", mean_absolute_error(y_train, y_hat_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tWsgRfF1Zeqm"},"outputs":[],"source":["# validation (20% of controls)\n","\n","print(\"RMSE:\",math.sqrt(mean_squared_error(targets_ctrls_test, Pred_ctrls)))\n","print(\"R2:\", r2_score(targets_ctrls_test, Pred_ctrls))\n","print(\"MAE:\", mean_absolute_error(targets_ctrls_test, Pred_ctrls))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfEeQ7ZXZiZ4"},"outputs":[],"source":["# testing set using a combination of all cases and controls together (Testing set)\n","\n","print(\"RMSE:\",math.sqrt(mean_squared_error(y_conc, y_hat_conc)))\n","print(\"R2:\", r2_score(y_conc, y_hat_conc))\n","print(\"MAE:\", mean_absolute_error(y_conc, y_hat_conc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3iDXoU28DAFV"},"outputs":[],"source":["# Plotting Actual vs Predicted scatter plot\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot()\n","\n","ax1.scatter(y_train, y_hat_train, alpha = 0.3, label = 'Training')\n","ax1.scatter(targets_ctrls_test, Pred_ctrls, label = 'Validation')\n","plt.legend(loc='lower right')\n","plt.xlabel('Actual', size = 13);\n","plt.ylabel('Predicted', size = 13);\n","plt.title('Actual TG vs Predicted TG')\n","plt.ylim(0,5.5)\n","plt.xlim(0,5.5)\n","plt.plot([0,5.5],[0,5.5], 'r')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-THjhdsWxJh"},"outputs":[],"source":["# Plotting dist/scatter plot for residuals (testing 20%)\n","\n","g=sns.jointplot(data = (targets_ctrls_test -Pred_ctrls).values).set_axis_labels('Predicted Triglycerides', 'Residuals')\n","g.fig.suptitle(\"Residual Plot (Validation)\", y= 1.01, size = 13)\n","for ax in (g.ax_joint, g.ax_marg_x):\n","    ax.axhline(0, ls='--', lw=3)\n","g.plot_marginals(sns.histplot, kde=True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VITVfnURegPw"},"outputs":[],"source":["# Plotting dist/scatter plot for residuals (training 80%)\n","\n","g=sns.jointplot(data = (y_train- y_hat_train).values).set_axis_labels('Predicted Triglycerides', 'Residuals')\n","g.fig.suptitle(\"Residual Plot (Train)\", y= 1.01, size = 13)\n","for ax in (g.ax_joint, g.ax_marg_x):\n","    ax.axhline(0, ls='--', lw=3)\n","g.plot_marginals(sns.histplot, kde=True)\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5nAN8FqEmZEB"},"source":["Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"e8-NRZZ6Odx-"},"source":["Grouping the y_hat into quartiles"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GnmzJ_66OeoA"},"outputs":[],"source":["# y_hat is split according to CaConRel value 0 (Controls)\n","\n","y_hat_conc_ctrl = y_hat_conc[working_df_males['CaConRel'][x_conc.index]==0]\n","y_hat_conc_cases = y_hat_conc[working_df_males['CaConRel'][x_conc.index]==1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KiVCnAAGOla5"},"outputs":[],"source":["# separated y_hat_conc_ctrl into quartiles. The intervals will be used to split y_hat_conc\n","\n","pd.qcut(y_hat_conc_ctrl, q=4,labels=['1', \n","                                '2', \n","                                '3',  \n","                                '4']) \n","\n","testcut_series, testcut_intervals = pd.qcut(y_hat_conc_ctrl, q=4,labels=['1','2', '3','4'],retbins=True) \n","\n","testcut_intervals"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PImXQPFqOovN"},"outputs":[],"source":["\n","GRS_TG = []\n","\n","for i in y_hat_conc: \n","  if i <= testcut_intervals[1]:\n","    GRS_TG.append(1)\n","  elif i <= testcut_intervals[2]:\n","    GRS_TG.append(2)\n","  elif i <= testcut_intervals[3]:\n","    GRS_TG.append(3)\n","  elif i > testcut_intervals[3]:\n","    GRS_TG.append(4)\n","  else:\n","    print('NaN')\n","\n","GRS_TG_index = pd.DataFrame(index=x_conc.index)\n","GRS_TG_index['GRS'] = GRS_TG\n","GRS_TG_index.value_counts()\n"]},{"cell_type":"markdown","metadata":{"id":"wIcBbJ2Kv2Po"},"source":["Running Logistic Regression on the categorical variable GRS_TG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9irt52VQ0BW"},"outputs":[],"source":["#getting the individuals(indices) from the Caconrel variable which correspond to the testing set indices. Thus, the cases.\n","\n","target = working_df_males['CaConRel']\n","\n","logreg_ytrain = target.loc[x_conc.index]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"we58MCwbQ904"},"outputs":[],"source":["# The predicted variable from the linear regression will be the used as the input in the logistic regression\n","\n","logreg_xtrain = y_hat_conc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAdFf5j66lx6"},"outputs":[],"source":["#Joining GRS_TG_index with logreg_ytrain (they both have the same index)\n","#so that we can get the crosstabs i.e. the frequency of for example cases and controls in each GRS group\n","\n","a = GRS_TG_index.join(pd.DataFrame(logreg_ytrain))\n","\n","a.columns = ['GRS', 'CaConRel']\n","pd.crosstab(a['GRS'],a['CaConRel'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-Cug0VRVbnu"},"outputs":[],"source":["# Percentages of cases and controls in each GRS group\n","\n","sns.heatmap(pd.crosstab(a['GRS'],a['CaConRel'],normalize='columns'),\n","            cmap=\"YlGnBu\", annot=True, cbar=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqP_bfitwC4f"},"outputs":[],"source":["# Getting dummy variables for the categorical variable GRS_TG\n","\n","GRS_TG_dum = pd.get_dummies(GRS_TG, drop_first=True, prefix=\"GRS\")\n","\n","x2 = GRS_TG_dum\n","y2 = logreg_ytrain.reset_index()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvLI7T1WW6H2"},"outputs":[],"source":["x2_index = x2.set_index(x_conc.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m7Ufwkp90CRx"},"outputs":[],"source":["# Fitting Logistic Regression Model\n","\n","x2 = sm.add_constant(x2)\n","reg_log2 = sm.Logit(y2['CaConRel'],x2.reset_index(drop= True))\n","results_log2 = reg_log2.fit()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1lAMxeu0ISN"},"outputs":[],"source":["results_log2.summary(alpha=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85iZ_4VD0QPK"},"outputs":[],"source":["# Calculating odds ratios and confidence intervals from exponential values of the coefficients\n","\n","df2 = pd.read_html(results_log2.summary().tables[1].as_html(),header=0,index_col=0)[0]\n","np.exp(df2['coef'].values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9U4A1HdAEkE"},"outputs":[],"source":["# Calculating confidence intervals from exponential values of the coefficients\n","\n","conf_int_res2 = results_log2.conf_int(alpha=0.1)\n","np.exp(conf_int_res2.values)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1iUSpCtFsETtIsCXhBquTnqnPWtLo0HRa","timestamp":1670405722819},{"file_id":"1MW1bLgb-rdwIFQ5mAimuX1AOnwHBCwig","timestamp":1670405224671},{"file_id":"12tnR59t3RyE499q3TO3FXwP5qT7U-kju","timestamp":1670402112816},{"file_id":"1WnRFzops3Yin3LNGm_ThK87Dpkpt0Xp3","timestamp":1670398522820},{"file_id":"1-c_JT4PH3-5Z5fRgwKt3PvJA55kkV77P","timestamp":1669894287311},{"file_id":"15nbH-DuObhQy_C43sMTib9C-spxhyG_k","timestamp":1669890105409},{"file_id":"1Ab2FTKDzGkfd45PXoR0XOJd5bHd-2VDR","timestamp":1669208286707},{"file_id":"1JycU4rtG0Iu7lf8_eklFhWwcheKOBt00","timestamp":1669205223399},{"file_id":"1GHlUbTlQW0w3NqXm5UH0oC-DuKu4S7TZ","timestamp":1669204396554},{"file_id":"1yyAlmFxe98lPzQsOfyTvL7WPb3GJwlZh","timestamp":1668685109818},{"file_id":"1FjS0s8qlc01Go9sZUk3hkL2ocR6jledu","timestamp":1668016163059},{"file_id":"15syzJ-Jpv6rIv71eqViWWGaXAv1RybS1","timestamp":1666892466044},{"file_id":"16WCI3-DPelzX78GzTZcsfMjiI3kwxpwR","timestamp":1652276371163},{"file_id":"1diE897T11mYFukUnD8AndZKXsNiuW9Qo","timestamp":1616926644678},{"file_id":"1BGDHwySo37Aw5x-LB7PpzSmGtx0ZFUdp","timestamp":1614194888333},{"file_id":"10ylm40_oZmlqR_9lr65mn-qcHonYzqv3","timestamp":1610462451109},{"file_id":"1s0-5-8b6Pk43Si3Y8Ydsz45U2HnDHWj6","timestamp":1608148949086}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}